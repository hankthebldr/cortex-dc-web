# Docker Compose - Complete Cortex DC Platform for K8s Validation
# This file orchestrates all services for local testing before K8s deployment
# Optimized for scale and production readiness

version: '3.9'

services:
  # ======================
  # Database: PostgreSQL
  # ======================
  postgres:
    image: postgres:16-alpine
    container_name: cortex-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: cortex
      POSTGRES_USER: cortex
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-cortex_secure_password}
      POSTGRES_MULTIPLE_DATABASES: keycloak
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-postgres.sh:/docker-entrypoint-initdb.d/init-postgres.sh:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U cortex -d cortex"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - cortex-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ======================
  # Authentication: Keycloak
  # ======================
  keycloak:
    image: quay.io/keycloak/keycloak:23.0.3
    container_name: cortex-keycloak
    restart: unless-stopped
    command:
      - start-dev
    environment:
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://postgres:5432/keycloak
      KC_DB_USERNAME: cortex
      KC_DB_PASSWORD: ${POSTGRES_PASSWORD:-cortex_secure_password}
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: ${KEYCLOAK_ADMIN_PASSWORD:-admin_password}
      KC_HOSTNAME: localhost
      KC_HOSTNAME_STRICT: false
      KC_HOSTNAME_STRICT_HTTPS: false
      KC_HTTP_ENABLED: true
      KC_HTTP_PORT: 8180
      KC_PROXY: edge
      KC_HEALTH_ENABLED: true
    ports:
      - "8180:8180"
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - keycloak_data:/opt/keycloak/data
    healthcheck:
      test: ["CMD-SHELL", "exec 3<>/dev/tcp/localhost/8180 && echo -e 'GET /health/ready HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n' >&3 && cat <&3 | grep -q '200 OK'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - cortex-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ======================
  # Object Storage: MinIO
  # ======================
  minio:
    image: minio/minio:RELEASE.2024-01-01T16-36-33Z
    container_name: cortex-minio
    restart: unless-stopped
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin_password}
      MINIO_BROWSER: "on"
      MINIO_PROMETHEUS_AUTH_TYPE: public
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 10s
    networks:
      - cortex-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # MinIO bucket initialization
  minio-init:
    image: minio/mc:latest
    container_name: cortex-minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc config host add minio http://minio:9000 ${MINIO_ROOT_USER:-minioadmin} ${MINIO_ROOT_PASSWORD:-minioadmin_password}) do echo 'Waiting for MinIO...' && sleep 1; done;
      /usr/bin/mc mb minio/cortex-documents || true;
      /usr/bin/mc mb minio/cortex-uploads || true;
      /usr/bin/mc mb minio/cortex-exports || true;
      /usr/bin/mc policy set download minio/cortex-documents;
      /usr/bin/mc policy set download minio/cortex-uploads;
      /usr/bin/mc policy set download minio/cortex-exports;
      echo 'MinIO buckets initialized successfully';
      exit 0;
      "
    networks:
      - cortex-network

  # ======================
  # Cache: Redis
  # ======================
  redis:
    image: redis:7-alpine
    container_name: cortex-redis
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD:-redis_password} --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--pass", "${REDIS_PASSWORD:-redis_password}", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 5s
    networks:
      - cortex-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

  # ======================
  # Message Queue: NATS
  # ======================
  nats:
    image: nats:2.10-alpine
    container_name: cortex-nats
    restart: unless-stopped
    command: "--jetstream --store_dir=/data --http_port=8222 --max_payload=8388608"
    ports:
      - "4222:4222"
      - "8222:8222"
      - "6222:6222"
    volumes:
      - nats_data:/data
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8222/healthz"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 5s
    networks:
      - cortex-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

  # ======================
  # API Server (Express)
  # ======================
  api-server:
    build:
      context: .
      dockerfile: packages/api-server/Dockerfile
      args:
        NODE_ENV: production
    image: cortex-api-server:latest
    container_name: cortex-api
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 8080
      HOST: 0.0.0.0

      # Database
      DATABASE_URL: postgresql://cortex:${POSTGRES_PASSWORD:-cortex_secure_password}@postgres:5432/cortex

      # Deployment mode
      DEPLOYMENT_MODE: self-hosted

      # Keycloak
      KEYCLOAK_URL: http://keycloak:8180
      KEYCLOAK_REALM: cortex
      KEYCLOAK_CLIENT_ID: cortex-api
      KEYCLOAK_CLIENT_SECRET: ${KEYCLOAK_CLIENT_SECRET}

      # MinIO
      MINIO_ENDPOINT: minio
      MINIO_PORT: 9000
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin_password}
      MINIO_USE_SSL: false

      # Redis
      REDIS_URL: redis://:${REDIS_PASSWORD:-redis_password}@redis:6379

      # NATS
      NATS_URL: nats://nats:4222

      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-info}
    ports:
      - "8080:8080"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
      nats:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:8080/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - cortex-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    profiles:
      - full

  # ======================
  # Firebase Functions (Microservice)
  # ======================
  functions:
    build:
      context: ./functions
      dockerfile: Dockerfile
    image: cortex-functions:latest
    container_name: cortex-functions
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 8081
      HOST: 0.0.0.0

      # For self-hosted mode, functions can connect to API server
      API_SERVER_URL: http://api-server:8080
      DEPLOYMENT_MODE: ${DEPLOYMENT_MODE:-firebase}

      LOG_LEVEL: ${LOG_LEVEL:-info}
    ports:
      - "8081:8081"
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:8081/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    networks:
      - cortex-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # ======================
  # Frontend (Next.js)
  # ======================
  web:
    build:
      context: .
      dockerfile: apps/web/Dockerfile
      args:
        NEXT_PUBLIC_API_URL: http://localhost:8080
        NEXT_PUBLIC_KEYCLOAK_URL: http://localhost:8180
        NEXT_PUBLIC_KEYCLOAK_REALM: cortex
        NEXT_PUBLIC_KEYCLOAK_CLIENT_ID: cortex-web
        NEXT_PUBLIC_DEPLOYMENT_MODE: ${DEPLOYMENT_MODE:-firebase}
    image: cortex-web:latest
    container_name: cortex-web
    restart: unless-stopped
    environment:
      NODE_ENV: production

      # API Configuration (runtime)
      NEXT_PUBLIC_API_URL: http://localhost:8080

      # Keycloak Configuration (runtime)
      NEXT_PUBLIC_KEYCLOAK_URL: http://localhost:8180
      NEXT_PUBLIC_KEYCLOAK_REALM: cortex
      NEXT_PUBLIC_KEYCLOAK_CLIENT_ID: cortex-web

      # Feature Flags
      NEXT_PUBLIC_DEPLOYMENT_MODE: ${DEPLOYMENT_MODE:-firebase}
      NEXT_PUBLIC_USE_BACKEND_API: ${USE_BACKEND_API:-false}
    ports:
      - "3000:3000"
    depends_on:
      functions:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/api/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - cortex-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ======================
  # Monitoring: Prometheus
  # ======================
  prometheus:
    image: prom/prometheus:latest
    container_name: cortex-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - cortex-network
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.1'
          memory: 256M

  # ======================
  # Monitoring: Grafana
  # ======================
  grafana:
    image: grafana/grafana:latest
    container_name: cortex-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: false
      GF_SERVER_ROOT_URL: http://localhost:3001
      GF_INSTALL_PLUGINS: grafana-piechart-panel
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - cortex-network
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

# ======================
# Volumes
# ======================
volumes:
  postgres_data:
    driver: local
  keycloak_data:
    driver: local
  minio_data:
    driver: local
  redis_data:
    driver: local
  nats_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

# ======================
# Networks
# ======================
networks:
  cortex-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16
          gateway: 172.28.0.1

# ======================
# Usage Instructions
# ======================
# Start basic services (web + functions):
#   docker-compose up -d
#
# Start full self-hosted stack (with api-server):
#   docker-compose --profile full up -d
#
# Start with monitoring:
#   docker-compose --profile monitoring up -d
#
# Start everything:
#   docker-compose --profile full --profile monitoring up -d
#
# View logs:
#   docker-compose logs -f [service-name]
#
# Check service health:
#   docker-compose ps
#
# Stop all services:
#   docker-compose down
#
# Remove all data:
#   docker-compose down -v
#
# Build and start:
#   docker-compose up -d --build
#
# Scale services (K8s simulation):
#   docker-compose --profile full up -d --scale functions=3
